---
title: "具身智能技术路线入门"
date: 2026-01-16 
categories: [Embodied AI]
tags: [Embodied AI]
---

本文基于YunlongDong 的具身智能基础技术路线Talk进行总结

![figure1]({{ "/assets/img/intro2eai.png" | relative_url }})


## 检测分割

### SAM系列

* [SAM](https://github.com/facebookresearch/segment-anything):进行图片level的分割
* [SAM2](https://github.com/facebookresearch/sam2): 进行video level的分割
* [SAM3](https://github.com/facebookresearch/sam3):promptable segmentation in images and videos
  * 衍生产品: [SAM3D](https://github.com/facebookresearch/sam-3d-objects) 可以进行3D物品生成也可以进行人体生成有 **object** 和**body** 两个版本



## 数据

### Video

* [**Mimic Play**](https://github.com/j96w/MimicPlay)
![figure1]({{ "/assets/img/method_fig.png" | relative_url }})

* [**Vid2Robot**](https://vid2robot.github.io/)

<b><i style="color:#7b5aa6">更多paper可以参考(这个仓库好久没更新了后续fork完会持续更新)</i></b>:

*  https://github.com/H-Freax/Awesome-Video-Robotic-Papers 



### 轻量级的硬件收集示范数据

* **UMI** 
* **DexCap**:手套
* **HIRO Hand** :套在手指上的设备来收集示范数据

### 重量级的硬件收集

* **VR** 
* **外骨骼**

### 生成式仿真

* **RoboGen** 
* **Gen2Sim**
* **RoboTwin**
* **InternData-A1** 
* **MimicGen** 

这也是我最focus 的一个方向所以更多阅读paperlist会在后续开源

## 动作执行

### Imitation Learning

**ACT**:

**Diffusion Policy** :

### Affordance:检测物品的可操作部分

**RoboAffordance**:

**AffordPose** :

**SceneFun3D** :

<b><i style="color:#7b5aa6">更多paper可以参考</i></b>: https://github.com/hq-King/Awesome-Affordance-Learning

### 大模型的应用

#### 利用大模型的QA来采取action

**ManipLLM** :

**ManipVQA** :

#### 大模型的planning 能力

### World Model

**3D VLA** 

**LAPO** 



# 高质量Paper关注list

**高质量会议与期刊（论文检索时重点关注）**
Science Robotics, TRO, IJRR, JFR, RSS, RAL, IROS, ICRA, ICCV, ECCV, ICML, CVPR, NeurIPS, CoRL, ICLR, AAAI, ACL

**长期跟进研究进展与选题调研**

- Awesome Humanoid Robot Learning（Yanjie Ze）：[repo](https://github.com/YanjieZe/awesome-humanoid-robot-learning)
- Paper Reading List（DeepTimber Community）：[repo](https://github.com/DeepTimber-Robot-Lab/Paper-Reading-List)
- Paper List（Yanjie Ze）：[repo](https://github.com/YanjieZe/Paper-List)
- RoboScholar / Embodied AI Paper List（Tianxing Chen）：[repo](https://github.com/TianxingChen/Paper-List-For-EmbodiedAI)
- SOTA Paper Rating（Weiyang Jin）：[website](https://waynejin0918.github.io/SOTA-paper-rating.io/)
- Awesome LLM Robotics：[repo](https://github.com/GT-RIPL/Awesome-LLM-Robotics)
- Awesome Video Robotic Papers：[repo](https://github.com/H-Freax/Awesome-Video-Robotic-Papers)
- Awesome Embodied Robotics and Agent：[repo](https://github.com/zchoi/Awesome-Embodied-Robotics-and-Agent)
- awesome-embodied-vla / va / vln：[repo](https://github.com/jonyzhang2023/awesome-embodied-vla-va-vln)
- Awesome Affordance Learning：[repo](https://github.com/hq-King/Awesome-Affordance-Learning)
- Embodied AI Paper TopConf：[repo](https://github.com/Songwxuan/Embodied-AI-Paper-TopConf)
- Awesome **RL-VLA** for Robotic Manipulation (Haoyuan Deng)：[repo](https://github.com/Denghaoyuan123/Awesome-RL-VLA)
